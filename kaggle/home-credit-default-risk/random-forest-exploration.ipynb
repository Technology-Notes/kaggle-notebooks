{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "from IPython.display import FileLink, display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import skew\n",
    "from scipy.special import boxcox1p\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('./data')\n",
    "PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Credit Default Risk: feature engineering and RF benchark\n",
    "\n",
    "This notebook walks through the Home Credit Default Risk dataset, attempting to find features that improve upon a RandomForest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Download and extract dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv.zip: Downloaded 117KB of 117KB to {PATH}\n",
      "application_test.csv.zip: Downloaded 6MB of 6MB to {PATH}\n",
      "application_train.csv.zip: Downloaded 34MB of 34MB to {PATH}\n",
      "bureau.csv.zip: Downloaded 36MB of 36MB to {PATH}\n",
      "bureau_balance.csv.zip: Downloaded 61MB of 61MB to {PATH}\n",
      "previous_application.csv.zip: Downloaded 74MB of 74MB to {PATH}\n",
      "credit_card_balance.csv.zip: Downloaded 94MB of 94MB to {PATH}\n",
      "POS_CASH_balance.csv.zip: Downloaded 106MB of 106MB to {PATH}\n",
      "installments_payments.csv.zip: Downloaded 267MB of 267MB to {PATH}\n",
      "HomeCredit_columns_description.csv: Downloaded 37KB of 37KB to {PATH}\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c home-credit-default-risk --path={PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for file in os.listdir(PATH):\n",
    "    if not file.endswith('zip'):\n",
    "        continue\n",
    "    \n",
    "    file_path = PATH / file\n",
    "\n",
    "    !unzip -f -q -d {PATH} {file_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train = pd.read_csv(PATH / 'application_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = application_train.pop('TARGET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_test = pd.read_csv(PATH / 'application_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([application_train, application_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare columns\n",
    "\n",
    "I'll start with the most basic processing, converting all categorical columns to Pandas categories. Any ordinal categorical columns will also be ordered with their categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    dict(name='SK_ID_CURR', type='cont'),\n",
    "    dict(name='NAME_CONTRACT_TYPE', type='cat'),\n",
    "    dict(name='CODE_GENDER', type='cat'),\n",
    "    dict(name='FLAG_OWN_CAR', type='cat'),\n",
    "    dict(name='FLAG_OWN_REALTY', type='cat'),\n",
    "    dict(name='CNT_CHILDREN', type='cat'),\n",
    "    dict(name='AMT_INCOME_TOTAL', type='cont'),\n",
    "    dict(name='AMT_CREDIT', type='cont'),\n",
    "    dict(name='AMT_ANNUITY', type='cont'),\n",
    "    dict(name='AMT_GOODS_PRICE', type='cont'),\n",
    "    dict(name='NAME_TYPE_SUITE', type='cat'),\n",
    "    dict(name='NAME_INCOME_TYPE', type='cat'),\n",
    "\n",
    "    dict(\n",
    "        name='NAME_EDUCATION_TYPE', type='ord', cats=[\n",
    "            'Incomplete higher', 'Lower secondary',\n",
    "            'Secondary / secondary special', 'Higher education',\n",
    "            'Academic degree']),\n",
    "    \n",
    "    dict(name='NAME_FAMILY_STATUS', type='cat'),\n",
    "    dict(name='NAME_HOUSING_TYPE', type='cat'),\n",
    "    dict(name='REGION_POPULATION_RELATIVE', type='cont'),\n",
    "    dict(name='DAYS_BIRTH', type='cont'),\n",
    "    dict(name='DAYS_EMPLOYED', type='cont'),\n",
    "    dict(name='DAYS_REGISTRATION', type='cont'),\n",
    "    dict(name='DAYS_ID_PUBLISH', type='cont'),\n",
    "    dict(name='OWN_CAR_AGE', type='cont'),\n",
    "    dict(name='FLAG_MOBIL', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_EMP_PHONE', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_WORK_PHONE', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_CONT_MOBILE', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_PHONE', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_EMAIL', type='ord', cats=[0, 1]),\n",
    "    dict(name='OCCUPATION_TYPE', type='cat'),\n",
    "    dict(name='CNT_FAM_MEMBERS', type='cont'),\n",
    "    dict(name='REGION_RATING_CLIENT', type='ord', cats=[1, 2, 3]),\n",
    "    dict(name='REGION_RATING_CLIENT_W_CITY', type='ord', cats=[1, 2, 3]),\n",
    "    dict(name='WEEKDAY_APPR_PROCESS_START', type='cat'),\n",
    "    dict(name='HOUR_APPR_PROCESS_START', type='cat'),\n",
    "    dict(name='REG_REGION_NOT_LIVE_REGION', type='ord', cats=[0, 1]),\n",
    "    dict(name='REG_REGION_NOT_WORK_REGION', type='ord', cats=[0, 1]),\n",
    "    dict(name='LIVE_REGION_NOT_WORK_REGION', type='ord', cats=[0, 1]),\n",
    "    dict(name='REG_CITY_NOT_LIVE_CITY', type='ord', cats=[0, 1]),\n",
    "    dict(name='REG_CITY_NOT_WORK_CITY', type='ord', cats=[0, 1]),\n",
    "    dict(name='LIVE_CITY_NOT_WORK_CITY', type='ord', cats=[0, 1]),\n",
    "    dict(name='ORGANIZATION_TYPE', type='cat'),\n",
    "    dict(name='EXT_SOURCE_1', type='cont'),\n",
    "    dict(name='EXT_SOURCE_2', type='cont'),\n",
    "    dict(name='EXT_SOURCE_3', type='cont'),\n",
    "    dict(name='APARTMENTS_AVG', type='cont'),\n",
    "    dict(name='BASEMENTAREA_AVG', type='cont'),\n",
    "    dict(name='YEARS_BEGINEXPLUATATION_AVG', type='cont'),\n",
    "    dict(name='YEARS_BUILD_AVG', type='cont'),\n",
    "    dict(name='COMMONAREA_AVG', type='cont'),\n",
    "    dict(name='ELEVATORS_AVG', type='cont'),\n",
    "    dict(name='ENTRANCES_AVG', type='cont'),\n",
    "    dict(name='FLOORSMAX_AVG', type='cont'),\n",
    "    dict(name='FLOORSMIN_AVG', type='cont'),\n",
    "    dict(name='LANDAREA_AVG', type='cont'),\n",
    "    dict(name='LIVINGAPARTMENTS_AVG', type='cont'),\n",
    "    dict(name='LIVINGAREA_AVG', type='cont'),\n",
    "    dict(name='NONLIVINGAPARTMENTS_AVG', type='cont'),\n",
    "    dict(name='NONLIVINGAREA_AVG', type='cont'),\n",
    "    dict(name='APARTMENTS_MODE', type='cont'),\n",
    "    dict(name='BASEMENTAREA_MODE', type='cont'),\n",
    "    dict(name='YEARS_BEGINEXPLUATATION_MODE', type='cont'),\n",
    "    dict(name='YEARS_BUILD_MODE', type='cont'),\n",
    "    dict(name='COMMONAREA_MODE', type='cont'),\n",
    "    dict(name='ELEVATORS_MODE', type='cat'),\n",
    "    dict(name='ENTRANCES_MODE', type='cat'),\n",
    "    dict(name='FLOORSMAX_MODE', type='cat'),\n",
    "    dict(name='FLOORSMIN_MODE', type='cat'),\n",
    "    dict(name='LANDAREA_MODE', type='cont'),\n",
    "    dict(name='LIVINGAPARTMENTS_MODE', type='cont'),\n",
    "    dict(name='LIVINGAREA_MODE', type='cont'),\n",
    "    dict(name='NONLIVINGAPARTMENTS_MODE', type='cont'),\n",
    "    dict(name='NONLIVINGAREA_MODE', type='cont'),\n",
    "    dict(name='APARTMENTS_MEDI', type='cont'),\n",
    "    dict(name='BASEMENTAREA_MEDI', type='cont'),\n",
    "    dict(name='YEARS_BEGINEXPLUATATION_MEDI', type='cont'),\n",
    "    dict(name='YEARS_BUILD_MEDI', type='cont'),\n",
    "    dict(name='COMMONAREA_MEDI', type='cont'),\n",
    "    dict(name='ELEVATORS_MEDI', type='cont'),\n",
    "    dict(name='ENTRANCES_MEDI', type='cont'),\n",
    "    dict(name='FLOORSMAX_MEDI', type='cont'),\n",
    "    dict(name='FLOORSMIN_MEDI', type='cont'),\n",
    "    dict(name='LANDAREA_MEDI', type='cont'),\n",
    "    dict(name='LIVINGAPARTMENTS_MEDI', type='cont'),\n",
    "    dict(name='LIVINGAREA_MEDI', type='cont'),\n",
    "    dict(name='NONLIVINGAPARTMENTS_MEDI', type='cont'),\n",
    "    dict(name='NONLIVINGAREA_MEDI', type='cont'),\n",
    "    dict(name='FONDKAPREMONT_MODE', type='cat'),\n",
    "    dict(name='HOUSETYPE_MODE', type='cat'),\n",
    "    dict(name='TOTALAREA_MODE', type='cont'),\n",
    "    dict(name='WALLSMATERIAL_MODE', type='cat'),\n",
    "    dict(name='EMERGENCYSTATE_MODE', type='ord', cats=['No', 'Yes']),\n",
    "    dict(name='OBS_30_CNT_SOCIAL_CIRCLE', type='cont'),\n",
    "    dict(name='DEF_30_CNT_SOCIAL_CIRCLE', type='cont'),\n",
    "    dict(name='OBS_60_CNT_SOCIAL_CIRCLE', type='cont'),\n",
    "    dict(name='DEF_60_CNT_SOCIAL_CIRCLE', type='cont'),\n",
    "    dict(name='DAYS_LAST_PHONE_CHANGE', type='cont'),\n",
    "    dict(name='FLAG_DOCUMENT_2', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_DOCUMENT_3', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_DOCUMENT_4', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_DOCUMENT_5', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_DOCUMENT_6', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_DOCUMENT_7', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_DOCUMENT_8', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_DOCUMENT_9', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_DOCUMENT_10', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_DOCUMENT_11', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_DOCUMENT_12', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_DOCUMENT_13', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_DOCUMENT_14', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_DOCUMENT_15', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_DOCUMENT_16', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_DOCUMENT_17', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_DOCUMENT_18', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_DOCUMENT_19', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_DOCUMENT_20', type='ord', cats=[0, 1]),\n",
    "    dict(name='FLAG_DOCUMENT_21', type='ord', cats=[0, 1]),\n",
    "    dict(name='AMT_REQ_CREDIT_BUREAU_HOUR', type='cont'),\n",
    "    dict(name='AMT_REQ_CREDIT_BUREAU_DAY', type='cont'),\n",
    "    dict(name='AMT_REQ_CREDIT_BUREAU_WEEK', type='cont'),\n",
    "    dict(name='AMT_REQ_CREDIT_BUREAU_MON', type='cont'),\n",
    "    dict(name='AMT_REQ_CREDIT_BUREAU_QRT', type='cont'),\n",
    "    dict(name='AMT_REQ_CREDIT_BUREAU_YEAR', type='cont')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.DAYS_EMPLOYED = all_data.DAYS_EMPLOYED * -1\n",
    "all_data.DAYS_REGISTRATION = all_data.DAYS_REGISTRATION * -1\n",
    "all_data.DAYS_BIRTH = all_data.DAYS_BIRTH * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_desc in columns:\n",
    "    col = col_desc['name']\n",
    "    \n",
    "    if col_desc['type'] == 'cat':\n",
    "        all_data[col] = all_data[col].astype('category').cat.as_ordered()\n",
    "    elif col_desc['type'] == 'ord':\n",
    "        all_data[col] = (\n",
    "            all_data[col].astype('category').cat.set_categories(\n",
    "                col_desc['cats'], ordered=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Advertising', 'Agriculture', 'Bank', 'Business Entity Type 1',\n",
      "       'Business Entity Type 2', 'Business Entity Type 3', 'Cleaning',\n",
      "       'Construction', 'Culture', 'Electricity', 'Emergency', 'Government',\n",
      "       'Hotel', 'Housing', 'Industry: type 1', 'Industry: type 10',\n",
      "       'Industry: type 11', 'Industry: type 12', 'Industry: type 13',\n",
      "       'Industry: type 2', 'Industry: type 3', 'Industry: type 4',\n",
      "       'Industry: type 5', 'Industry: type 6', 'Industry: type 7',\n",
      "       'Industry: type 8', 'Industry: type 9', 'Insurance', 'Kindergarten',\n",
      "       'Legal Services', 'Medicine', 'Military', 'Mobile', 'Other', 'Police',\n",
      "       'Postal', 'Realtor', 'Religion', 'Restaurant', 'School', 'Security',\n",
      "       'Security Ministries', 'Self-employed', 'Services', 'Telecom',\n",
      "       'Trade: type 1', 'Trade: type 2', 'Trade: type 3', 'Trade: type 4',\n",
      "       'Trade: type 5', 'Trade: type 6', 'Trade: type 7', 'Transport: type 1',\n",
      "       'Transport: type 2', 'Transport: type 3', 'Transport: type 4',\n",
      "       'University', 'XNA'],\n",
      "      dtype='object')\n",
      "Int64Index([0, 1], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(all_data['ORGANIZATION_TYPE'].cat.categories)\n",
    "print(all_data['FLAG_DOCUMENT_3'].cat.categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_columns = [c['name'] for c in columns if c['type'] == 'cont']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COMMONAREA_MEDI                 248360\n",
       "COMMONAREA_MODE                 248360\n",
       "COMMONAREA_AVG                  248360\n",
       "NONLIVINGAPARTMENTS_MEDI        246861\n",
       "NONLIVINGAPARTMENTS_AVG         246861\n",
       "NONLIVINGAPARTMENTS_MODE        246861\n",
       "LIVINGAPARTMENTS_AVG            242979\n",
       "LIVINGAPARTMENTS_MODE           242979\n",
       "LIVINGAPARTMENTS_MEDI           242979\n",
       "FLOORSMIN_MEDI                  241108\n",
       "FLOORSMIN_AVG                   241108\n",
       "YEARS_BUILD_MODE                236306\n",
       "YEARS_BUILD_AVG                 236306\n",
       "YEARS_BUILD_MEDI                236306\n",
       "OWN_CAR_AGE                     235241\n",
       "LANDAREA_AVG                    210844\n",
       "LANDAREA_MEDI                   210844\n",
       "LANDAREA_MODE                   210844\n",
       "BASEMENTAREA_MEDI               207584\n",
       "BASEMENTAREA_MODE               207584\n",
       "BASEMENTAREA_AVG                207584\n",
       "NONLIVINGAREA_AVG               195766\n",
       "NONLIVINGAREA_MEDI              195766\n",
       "NONLIVINGAREA_MODE              195766\n",
       "EXT_SOURCE_1                    193910\n",
       "ELEVATORS_MEDI                  189080\n",
       "ELEVATORS_AVG                   189080\n",
       "APARTMENTS_AVG                  179948\n",
       "APARTMENTS_MEDI                 179948\n",
       "APARTMENTS_MODE                 179948\n",
       "ENTRANCES_MEDI                  178407\n",
       "ENTRANCES_AVG                   178407\n",
       "LIVINGAREA_AVG                  177902\n",
       "LIVINGAREA_MODE                 177902\n",
       "LIVINGAREA_MEDI                 177902\n",
       "FLOORSMAX_AVG                   176341\n",
       "FLOORSMAX_MEDI                  176341\n",
       "YEARS_BEGINEXPLUATATION_MEDI    172863\n",
       "YEARS_BEGINEXPLUATATION_MODE    172863\n",
       "YEARS_BEGINEXPLUATATION_AVG     172863\n",
       "TOTALAREA_MODE                  171055\n",
       "EXT_SOURCE_3                     69633\n",
       "AMT_REQ_CREDIT_BUREAU_YEAR       47568\n",
       "AMT_REQ_CREDIT_BUREAU_QRT        47568\n",
       "AMT_REQ_CREDIT_BUREAU_HOUR       47568\n",
       "AMT_REQ_CREDIT_BUREAU_WEEK       47568\n",
       "AMT_REQ_CREDIT_BUREAU_DAY        47568\n",
       "AMT_REQ_CREDIT_BUREAU_MON        47568\n",
       "OBS_60_CNT_SOCIAL_CIRCLE          1050\n",
       "DEF_30_CNT_SOCIAL_CIRCLE          1050\n",
       "OBS_30_CNT_SOCIAL_CIRCLE          1050\n",
       "DEF_60_CNT_SOCIAL_CIRCLE          1050\n",
       "EXT_SOURCE_2                       668\n",
       "AMT_GOODS_PRICE                    278\n",
       "AMT_ANNUITY                         36\n",
       "CNT_FAM_MEMBERS                      2\n",
       "DAYS_LAST_PHONE_CHANGE               1\n",
       "AMT_INCOME_TOTAL                     0\n",
       "AMT_CREDIT                           0\n",
       "DAYS_REGISTRATION                    0\n",
       "REGION_POPULATION_RELATIVE           0\n",
       "DAYS_BIRTH                           0\n",
       "DAYS_EMPLOYED                        0\n",
       "DAYS_ID_PUBLISH                      0\n",
       "SK_ID_CURR                           0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000):\n",
    "    display(all_data[continuous_columns].isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some columns it makes sense to deal with NAs by setting to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.loc[all_data['CNT_FAM_MEMBERS'].isnull(),'CNT_FAM_MEMBERS' ] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For others, I'll impute the data by taking the median and add a `is_na` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name, col in all_data[continuous_columns].items():\n",
    "    if col.isnull().sum() > 0:\n",
    "        all_data[f'{col_name}_is_na'] = col.isnull()\n",
    "        all_data[col_name] = all_data[col_name].fillna(all_data[col_name].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numericalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_numeric = numericalise(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_benchmark(inp, targs, num_splits=5, train_size=None):\n",
    "    kf = KFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
    "    model = RandomForestRegressor(n_jobs=-1, random_state=42)\n",
    "    scores = cross_val_score(model, inp[:train_size], targs[:train_size], cv=kf, scoring='roc_auc')\n",
    "    print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6475092013010153\n"
     ]
    }
   ],
   "source": [
    "rf_benchmark(all_data_numeric[:len(application_train)], target, train_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(application_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Count the previous applications.\n",
    "* One-hot encode categories.\n",
    "* Then average all the data.\n",
    "* Deal with NaNs.\n",
    "\n",
    "Thinking that feature combinations are going to be useful here. Might be nice to get a count of the number of loans rejected by type and so on. Might circle back to this depending on how important this feature is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_application = pd.read_csv(PATH / 'previous_application.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_counts = previous_application[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_cat_columns = [c for c in previous_application.columns if len(previous_application[c].unique()) < 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in prev_app_cat_columns:\n",
    "    previous_application[col] = previous_application[col].astype('category').cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_dummies = pd.get_dummies(\n",
    "    previous_application[prev_app_cat_columns], dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_application.drop(prev_app_cat_columns, axis=1, inplace=True)\n",
    "previous_application = pd.concat([previous_application, prev_app_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_application = previous_application.drop(['SK_ID_PREV'], axis=1).groupby('SK_ID_CURR').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_application = previous_application.join(prev_app_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_cont_columns = [c for c in previous_application.columns if c not in prev_app_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaNs with the median ()\n",
    "for col_name, col in previous_application[prev_app_cont_columns].items():\n",
    "    if col.isnull().sum() > 0:\n",
    "        previous_application[f'{col_name}_is_na'] = col.isnull()\n",
    "        previous_application[col_name] = previous_application[col_name].fillna(previous_application[col_name].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_prev = all_data_numeric.join(previous_application, on='SK_ID_CURR', rsuffix='_PREV_APP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name, col in all_data_prev.items():\n",
    "    if col.isnull().sum() > 0:\n",
    "        all_data_prev[f'{col_name}_is_na'] = all_data_prev[col_name].isna()\n",
    "        all_data_prev[col_name] = all_data_prev[col_name].fillna(all_data_prev[col_name].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6595987647394873\n"
     ]
    }
   ],
   "source": [
    "rf_benchmark(all_data_prev[:train_len], target, train_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit card balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One-hot encode categories.\n",
    "* Take a mean of the various balances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_balance = pd.read_csv(PATH / 'credit_card_balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_balance = pd.concat([\n",
    "    credit_card_balance.drop('NAME_CONTRACT_STATUS', axis=1),\n",
    "    pd.get_dummies(credit_card_balance['NAME_CONTRACT_STATUS'], prefix='cc_bal_status_')\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_prevs = credit_card_balance[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_balance = credit_card_balance.drop('SK_ID_PREV', axis=1).join(cc_prevs, on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_avgs = credit_card_balance.groupby('SK_ID_CURR').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_cc = all_data_prev.join(credit_card_avgs, on='SK_ID_CURR', rsuffix='_CC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name, col in all_data_cc.items():\n",
    "    if col.isnull().sum() > 0:\n",
    "        all_data_cc[f'{col_name}_is_na'] = all_data_cc[col_name].isna()\n",
    "        all_data_cc[col_name] = all_data_cc[col_name].fillna(all_data_cc[col_name].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6529709555980182\n"
     ]
    }
   ],
   "source": [
    "rf_benchmark(all_data_cc[:train_len], target, train_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit bureau data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau = pd.read_csv(PATH / 'bureau.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_balance = pd.read_csv(PATH / 'bureau_balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_balance = pd.concat([\n",
    "    bureau_balance,\n",
    "    pd.get_dummies(bureau_balance.STATUS, prefix='bureau_bal')], axis=1).drop(\n",
    "    'STATUS', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_balance_count = bureau_balance[['SK_ID_BUREAU', 'MONTHS_BALANCE']].groupby('SK_ID_BUREAU').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_balance = bureau_balance.drop('MONTHS_BALANCE', axis=1).join(month_balance_count, on='SK_ID_BUREAU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_balance = bureau_balance.groupby('SK_ID_BUREAU').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_cat_columns = [b for b in bureau.columns if bureau[b].dtype == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_dummies = pd.get_dummies(bureau[bureau_cat_columns], dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau = pd.concat([bureau.drop(bureau_cat_columns, axis=1), bureau_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_joined = bureau.join(bureau_balance, on='SK_ID_BUREAU', rsuffix='bb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bureau = bureau_joined[['SK_ID_CURR', 'SK_ID_BUREAU']].groupby('SK_ID_CURR').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_joined['SK_ID_BUREAU'] = bureau_joined['SK_ID_CURR'].map(num_bureau['SK_ID_BUREAU'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_bureau = bureau_joined.groupby('SK_ID_CURR').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_bureau = all_data_cc.join(avg_bureau, on='SK_ID_CURR', rsuffix='_CC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name, col in all_data_bureau.items():\n",
    "    if col.isnull().sum() > 0:\n",
    "        all_data_bureau[f'{col_name}_is_na'] = all_data_bureau[col_name].isna()\n",
    "        all_data_bureau[col_name] = all_data_bureau[col_name].fillna(\n",
    "            all_data_bureau[col_name].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6533579001522801\n"
     ]
    }
   ],
   "source": [
    "rf_benchmark(all_data_bureau[:train_len], target, train_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installment payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_payments = pd.read_csv('./data/installments_payments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_prevs = install_payments[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_payments = install_payments.drop('SK_ID_PREV', axis=1).join(install_prevs, on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_install_payments = install_payments.groupby('SK_ID_CURR').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_ip = all_data_bureau.join(avg_install_payments, on='SK_ID_CURR', rsuffix='_IP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name, col in all_data_ip.items():\n",
    "    if col.isnull().sum() > 0:\n",
    "        all_data_ip[f'{col_name}_is_na'] = all_data_ip[col_name].isna()\n",
    "        all_data_ip[col_name] = all_data_ip[col_name].fillna(all_data_ip[col_name].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6686260774977025\n"
     ]
    }
   ],
   "source": [
    "rf_benchmark(all_data_ip[:train_len], target, train_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cash_bal = pd.read_csv('./data/POS_CASH_balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cash_bal = pd.concat([pos_cash_bal, pd.get_dummies(pos_cash_bal.NAME_CONTRACT_STATUS)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_prevs = pos_cash_bal[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cash_bal['SK_ID_PREV'] = pos_cash_bal['SK_ID_CURR'].map(num_prevs['SK_ID_PREV'])\n",
    "avg_pos_cash_bal = pos_cash_bal.groupby('SK_ID_CURR').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_pos = all_data_bureau.join(avg_pos_cash_bal, on='SK_ID_CURR', rsuffix='_POS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name, col in all_data_pos.items():\n",
    "    if col.isnull().sum() > 0:\n",
    "        all_data_pos[f'{col_name}_is_na'] = all_data_pos[col_name].isna()\n",
    "        all_data_pos[col_name] = all_data_pos[col_name].fillna(\n",
    "            all_data_pos[col_name].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6658425218879651\n"
     ]
    }
   ],
   "source": [
    "rf_benchmark(all_data_pos[:train_len], target, train_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_pos.to_pickle(PATH / 'all_data_prepared.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
